{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HandsON ML with Scikit-Learn, Keras & TensorFlow  \n",
    "[데이터 자료 가져오기](https://github.com/rickiepark/handson-ml2)\n",
    "\n",
    "### 1장 . 한눈에 보는 머신러닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 머신러닝이란 ? \n",
    "- 데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학\n",
    "- 명시적 프로그래밍 없이 컴퓨터가 스스로 데이터를 학습하는 능력을 갖추게 하는 연구\n",
    "- 어떤 작업 T에 대한 컴퓨터 프로그래밍의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다. \n",
    "\n",
    "EX )   \n",
    "#### 스팸 필터 \n",
    "- 사용자 지정 스팸메일과 일반 메일의 샘플을 이용하여 스팸 메일 구분법을 학습  \n",
    "- 훈련 세트 - 시스템이 학습하는 데 사용하는 샘플 \n",
    "- 훈련 사례 - 각 훈련 데이터\n",
    "- 작업 T - 새로운 메일이 스팸인지 구분하는 것\n",
    "- 경험 E - 훈련 데이터\n",
    "- 성능 측정 P - 직접 정의 ex) 정확히 분류된 메일의 비율을 P로 정할수있다.  \n",
    "이 P를 Accuracy라고 부르며 분류작업에 사용된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 왜 머신러닝을 사용하는가?\n",
    "#### 전통적인 프로그래밍 방법으로 스팸 필터 만들기  \n",
    "- 먼저 스팸에 어떤 단어들이 주로 나타나는지 살펴본다. 제목에 나타나는 경향 또는 보낸이의 정보나 본문, 이메일의 다른 요소에서 어떠한 패턴을 감지할 수 있을 것이다.\n",
    "- 발견한 각 패턴을 감지하는 알고리즘을 작성하여 프로그램이 이런 패턴을 발견했을 때 그 메일을 스팸으로 분류하게 한다. \n",
    "- 프로그램을 테스트하고 론칭할 만큼 충분한 성능이 나올 때 까지 1단계와 2단계를 반복한다. \n",
    "  \n",
    "그러나 이 방법은 규칙이 점점 길고 복잡해지므로 유지 보수하기가 매우 힘들어진다. \n",
    "\n",
    "#### 머신러닝 기법에 기반을 둔 스팸 필터 만들기 \n",
    "- 일반 메일에 비해 자주 나타나는 패턴을 감지하여 어떤 단어와 구절이 스팸 메일을 판단하는 데 좋은 기준인지 자동으로 학습한다. \n",
    "- 머신러닝 기반의 스팸 필터는 사용자가 스팸으로 지정한 메일에 어떠한 반복되는 패턴을 자동으로 인식하고 별도의 작업을 하지 않아도 자동으로 이 단어를 스팸으로 분류한다.(자동으로 변화에 적응)  \n",
    "\n",
    "#### 데이터 마이닝 \n",
    "- ex) 스팸필터가 충분한 스팸 메일로 훈련되었다면 스팸을 예측하는 데 가장 좋은 단어 및 단어의 조합이 무엇인지 확인 가능   \n",
    "그러나 가끔 예상치 못한 연관 관계나 새로운 추세가 발견되기도 해서 우리는 이 변화를 조사함으로써 해당 문제를 더 잘 이해하게 한다.(추가적인 학습)  \n",
    "- 머신러닝을 적용하여 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견하는 것을 Data Mining 이라고 한다.  \n",
    "\n",
    "#### 머신러닝 적용이 뛰어난 분야 \n",
    "- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 \n",
    "- 전통적 방식으로는 해결 방법이 없는 복잡한 문제 \n",
    "- 유동적 환경\n",
    "- 복잡한 문제와 대량의 데이터에서 통찰얻기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 머신러닝 시스템의 종류\n",
    "- 지도학습과 비지도학습 , 준지도학습 , 강화학습 ( 사람의 감독하에 훈련하는지 아닌지 )\n",
    "- 온라인 학습과 배치 학습  ( 실시간으로 점진적 학습을 하는지 아닌지) \n",
    "- 사례 기반 학습과 모델 기반 학습 (단순하게 알고 있는 새 데이터 포인트를 비교하는 것인지 아니면 훈련 데이터 셋에서 패턴을 발견하여 예측 모델을 만드는지 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 지도학습과 비지도학습 \n",
    "#### 학습하는 동안의 감독 형태나 정보량에 따라 분류\n",
    "### A. 지도 학습\n",
    "- 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함된 경우의 작업 -> 분류,타깃 수치 예측(회귀) 등이 있다.\n",
    "- 분류는 전형적인 지도 학습 작업이며, 스팸 필터가 좋은 예\n",
    "- 예측 변수라 부르는 특성을 사용해 중고차 가격같은 타깃수치를 예측하는 회귀작업 (훈련하려면 레이블이 포함된 많은 데이터 필요) \n",
    "\n",
    "#### 지도 학습 알고리즘\n",
    "- K-최근접 이웃 \n",
    "- 선형 회귀와 로지스틱 회귀\n",
    "- 서포트 벡터 머신 (SVM) \n",
    "- 결정 트리와 랜덤포레스트\n",
    "- 신경망 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. 비지도 학습 \n",
    "- 훈련 데이터에 레이블이 없는 경우의 작업\n",
    "\n",
    "#### 비지도 학습 알고리즘 \n",
    "- 군집 ( K-평균 , DBSCAN, 계층 군집 분석 , 이상치 탐지와 특이치 탐지, 원 클래스 , 아이솔레이션 포레스트 )\n",
    "- 시각화와 차원 축소 ( 주 성분 분석, 커널 PCA , 지역적 선형 임베딩 , t-SNE )\n",
    "- 연관 규칙 학습 ( 어프라이어리 , 이클렛 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. 준지도 학습\n",
    "- 데이터에 레이블을 다는 것은 일반적으로 시간과 비용이 많이 듬\n",
    "- 레이블이 없는 샘플이 많고 레이블된 샘플은 적은 경우에 대한 작업 Ex) Google의 포토 호스팅 작업\n",
    "- 대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있다.\n",
    "- 비지도 학습 방식으로 순차적으로 훈련된 다음 전체 시스템이 지도 학습 방식으로 세밀하게 조정된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. 강화 학습\n",
    "- 학습하는 시스템을 에이전트라고 부르며 환경을 관찰하여 행동을 실행하고 그 결과로 보상 또는 벌점을 받는다.\n",
    "- 시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습.\n",
    "- 정책은 주어진 상황에서 에이전트가 어떤 선택을 해야할 지 정의한다. \n",
    "\n",
    "#### 강화학습의 예\n",
    "- 보행로봇\n",
    "- 알파고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 배치 학습과 온라인 학습 \n",
    "#### 입력 데이터의 스트림으로 부터 점진적으로 학습할 수 있는가 ? \n",
    "### A. 배치 학습 \n",
    "- 시스템이 점진적으로 학습할 수 없어서 가용한 데이터를 모두 훈련시켜야 함 .\n",
    "- 오프라인 학습 \n",
    "- 새로운 데이터에 대해 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야함. (교체) \n",
    "\n",
    "  \n",
    "### B. 온라인 학습\n",
    "- 데이터를 순차적으로 한개씩 또는 미니배치라고 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킵니다.\n",
    "- 학습단계가 빠르고 비용이 적게들어서 시스템은 데이터가 도착하는 대로 즉시 학습 가능\n",
    "- 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야하는 시스템에 적합하다.\n",
    "- 컴퓨터 한대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에도 용이( 외부 메모리 학습 )\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 사례 기반 학습과 모델 기반 학습 \n",
    "#### 어떻게 일반화 되는가?\n",
    "\n",
    "### A. 사례 기반 학습\n",
    "- 두 메일 사이의 유사도를 측정하여 스팸 메일과 유사한 메일을 구분하도록 스팸 필터를 프로그래밍 하는 것.\n",
    "- 공통으로 포함된 단어의 개수를 세어 공통 단어가 많으면 스팸으로 분류하는 과정을 예시로 들 수 있음.\n",
    "- 시스템이 훈련 샘플을 기억함으로써 학습 .\n",
    "- 유사도 측정을 통해 새로운 데이터와 학습한 샘플을 비교하면서 일반화\n",
    "- 새로운 샘플은 가장 비슷한 샘플 중 다수의 그룹으로 분류\n",
    "\n",
    "### B. 모델 기반 학습 \n",
    "- 샘플들의 모델을 만들어 예측에 사용하는 것  \n",
    "<교재 데이터 자료>  \n",
    "[OECD](https://homl.info/4)  \n",
    "[IMF](https://homl.info/5)  \n",
    "\n",
    "  \n",
    "    \n",
    "- 1인당 GDP라는 하나의 특성을 가진 삶의 만족도에 대한 선형 모델을 만듬   \n",
    "삶의 만족도 = a + b*1인당_GDP \n",
    "- 여기서 a와 b는 모델 파라미터라고 한다. \n",
    "- 이 모델 파라미터를 조정하여 어떤 선형 함수를 표현하는 모델을 얻을 수 있다.\n",
    "  \n",
    "    \n",
    "- 모델을 사용하기 전에 모델 파라미터 a 와 b를 정의해야한다.\n",
    "- 모델이 얼마나 좋은지 측정하는 효용함수(적합도함수) , 나쁜지를 측정하는 비용함수를 정의한다.\n",
    "- 선형 회귀에서는 모델 예측과 훈련 데이터 사이의 거리를 재는 비용함수를 사용한다. 이 거리를 최소화하는 것이 목표\n",
    "- 알고리즘에 훈련 데이터를 공급하여 가장 잘 맞는 선형 모델의 파라미터를 찾는다. -> 모델을 훈련시키는 것 \n",
    "- 데이터를 분석 -> 모델 선택 -> 훈련데이터로 모델을 훈련 -> 새로운 데이터에 모델 적용, 예측(추론) -> 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 머신러닝의 주요 도전 과제 \n",
    "- 학습 알고리즘을 선택해서 어떤 데이터에 훈련시키는 것이 ML의 주요 작업 \n",
    "- 나쁜데이터와 나쁜 알고리즘을 거르는 방법에 대해 알아보자 .\n",
    "\n",
    "#### 1.5.1 충분하지 않은 양의 훈련데이터 \n",
    "- 알고리즘이 잘 작동하려면 많은 데이터가 필요함 \n",
    "- 수천개 ~ 수백만 개의 데이터 필요 \n",
    "\n",
    "#### 1.5.2 대표성 없는 훈련데이터 \n",
    "- 일반화가 잘 되려면 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요 \n",
    "- 일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 매우 중요\n",
    "- 샘플이 작으면 샘플링 잡음 , 매우 큰 샘플도 추출 방법이 잘못되어있으면 대표성을 띠지 못하는 샘플링 편향 현상 발생\n",
    "\n",
    "#### 1.5.3 낮은 품질의 데이터\n",
    "- 훈련 데이터가 에러, 이상치, 잡음으로 가득한 경우 훈련 데이터의 정제가 필요 \n",
    "- 데이터 정제에 많은 시간을 투자\n",
    "- 훈련 데이터 정제가 필요한 경우   \n",
    " 1. 일부 샘플이 이상치라는게 명확하면 무시를 한다던지 수동으로 고치는 것이 좋다.  \n",
    " 2. 일부 샘플에 특성 몇 개가 누락된 경우 이 특성을 무시할 지 빠진 값을 채울지 이 특성을 넣은 모델과 제외한 훈련을 따로 훈련시킬 것인지 고려해야함.   \n",
    " \n",
    "#### 1.5.4 관련 없는 특성 \n",
    "- 특성 선택 및 특성 추출\n",
    "- 새로운 데이터를 수집해 새 특성 생성 \n",
    "\n",
    "#### 1.5.5 훈련 데이터의 과대적합 \n",
    "- 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어지는 경우 \n",
    "- 학습할 때 적용할 규제의 양은 하이퍼파라미터가 결정한다. \n",
    "- 머신러닝을 구축할 때 하이퍼 파라미터 튜닝은 매우 중요한 과정 \n",
    "\n",
    "#### 1.5.6 훈련 데이터의 과소적합\n",
    "- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못하는 경우\n",
    "- 해결 방안   \n",
    "모델 파라미터가 더 많은 강력한 모델을 선택하도록 한다.  \n",
    "학습 알고리즘에서 더 좋은 특성 제공  \n",
    "모델의 제약을 간소화 (규제 하이퍼파라미터 감소)   \n",
    "\n",
    "#### 1.5.7 요약 \n",
    "- 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 하는 것 \n",
    "- 여러 종류의 머신러닝 시스템 활용 \n",
    "- 훈련 세트에 데이터를 모아 학습 알고리즘에 주입하는 프로젝트 . 학습 알고리즘이 모델 기반이면 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정하고 새로운 데이터에서도 좋은 예측을 만들 거라 기대한다. 사례 기반인 경우 샘플을 기억하는 것이 학습이고 유사도 측정을 통해 학습한 샘플과 새로운 샘플을 비교하는 식으로 새로운 샘플에 일반화한다.\n",
    "- 훈련 세트가 너무 작거나 대표성이 없는 데이터거나 잡음이 많고 관련 없는 특성으로 오염되어 있다면 , 시스템이 작동하지 않음 \n",
    "- 모델이 너무 단순하거나 복잡하지 않아야함 \n",
    "- 모델을 평가하고 필요하다면 상세하게 튜닝해야하는 것이 가장 중요한 주제임 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 테스트와 검증 \n",
    "- 모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용하는 것.\n",
    "- 훈련 세트와 테스트 세트 두가지로 나눠 훈련 세트를 사용해 모델을 훈련한 뒤 테스트 세트를 사용하여 모델을 테스트함 .\n",
    "- 새로운 샘플에 대한 오류 비율을 일반화 오차라고 하며 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻음 .\n",
    "- 새로운 샘플에 모델이 얼마나 잘 작동할지 판단 \n",
    "\n",
    "#### 1.6.1 하이퍼 파라미터 튜닝과 모델 선택 \n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 연습문제 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
